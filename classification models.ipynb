{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9583687a","cell_type":"code","source":"import os\nos.environ[\"KAGGLE_CONFIG_DIR\"] = '/kaggle/input/brain-tumor-mri-dataset'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"611bccec","cell_type":"code","source":"!pip install scikit-learn\n!pip install seaborn\n!pip install plotly\n!pip install missingno","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c2d67425","cell_type":"code","source":"import sys\nimport os\nimport math\nimport pathlib\nimport numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib import rcParams\nrcParams['figure.dpi'] = 300\n%matplotlib inline\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications import ResNet152V2\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.applications import EfficientNetV2L\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import *\n\nfrom PIL import Image, ImageEnhance\nfrom tensorflow.keras.preprocessing.image import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"795a415b","cell_type":"code","source":"train_dir = pathlib.Path('/kaggle/input/brain-tumor-mri-dataset/Training')\ntest_dir = pathlib.Path('/kaggle/input/brain-tumor-mri-dataset/Testing')\nimg_height=224\nimg_width=224","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8e3fbf49","cell_type":"markdown","source":"# Image Augmentation","metadata":{}},{"id":"73e9733f","cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(0.2),\n    tf.keras.layers.RandomZoom(0.2),\n    tf.keras.layers.RandomContrast(0.2),\n    tf.keras.layers.RandomTranslation(0.1, 0.1),\n])\n\n# Normalization\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\n\n# Dataset loading\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    train_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(224, 224),\n    batch_size=32,\n    shuffle=True,\n    interpolation=\"bilinear\",\n    label_mode=\"int\",\n    follow_links=False,\n)\n\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\ntrain_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    train_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(224, 224),\n    batch_size=32,\n)\n\nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    test_dir,\n    image_size=(224, 224),\n    batch_size=32,\n)\ntest_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1ac98812","cell_type":"markdown","source":"# Visualize the data distribution","metadata":{}},{"id":"892c63c4","cell_type":"code","source":"ROOT_DIR = r\"/kaggle/input/brain-tumor-mri-dataset\"\nTRAIN_DIR = os.path.join(ROOT_DIR, 'Training')\nTEST_DIR = os.path.join(ROOT_DIR, 'Testing')\nassert os.path.isdir(ROOT_DIR) and os.path.isdir(TRAIN_DIR) and os.path.isdir(TEST_DIR)\nTUMOR_CLASS = ['meningioma', 'glioma', 'pituitary', 'notumor']\nIMAGE_DATA_PATHS = [os.path.join(TRAIN_DIR, tumor_class) for tumor_class in TUMOR_CLASS]\nTEST_DATA_PATHS = [os.path.join(TEST_DIR, tumor_class) for tumor_class in TUMOR_CLASS]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4d546935","cell_type":"code","source":"TEST_DATA_PATHS","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5be7c51d","cell_type":"code","source":"data_distribution_count = pd.Series([len(os.listdir(path)) for path in TEST_DATA_PATHS if os.path.exists(path) and os.path.isdir(path)],index = TUMOR_CLASS)\ndata_distribution_count","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0e588f6b","cell_type":"code","source":"data_distribution_count = pd.Series([len(os.listdir(path)) for path in IMAGE_DATA_PATHS if os.path.exists(path) and os.path.isdir(path)],index = TUMOR_CLASS)\ndata_distribution_count","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a8a9fe53","cell_type":"code","source":"def display_sample_images(paths, classes):\n    fig, axes = plt.subplots(nrows=1, ncols=len(paths), figsize=(18, 5))\n    for i, (path, cls) in enumerate(zip(paths, classes)):\n        image_file = os.listdir(path)[1]\n        image_path = os.path.join(path, image_file)\n        image = plt.imread(image_path, format='grayscale')\n\n        folder_name = os.path.basename(path)\n        axes[i].imshow(image, cmap='gray')\n        axes[i].set_title(folder_name)\n        axes[i].axis('off')\n    plt.show()\n\n\ndisplay_sample_images(IMAGE_DATA_PATHS, TUMOR_CLASS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bbe4a857-8075-4c74-9839-b78b3908d1c2","cell_type":"markdown","source":"# Function to create and train models","metadata":{}},{"id":"ee58c5aa-80e6-440f-8b9a-45326ec221f8","cell_type":"code","source":"def create_and_train_model(base_model, model_name, train_ds, val_ds, test_ds, num_classes=4, learning_rate=0.0001, epochs=100):\n    for layer in base_model.layers[:10]:\n        layer.trainable = False\n\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = Dropout(0.4)(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs=base_model.inputs, outputs=predictions)\n    model.compile(\n        optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999),\n        loss=tf.losses.SparseCategoricalCrossentropy(),\n        metrics=['accuracy']\n    )\n\n    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n    model_checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', save_best_only=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n\n    history = model.fit(\n        train_ds,\n        shuffle=True,\n        validation_data=test_ds,\n        epochs=epochs,\n        callbacks=[early_stop, model_checkpoint, reduce_lr]\n    )\n\n    model.save(f'{model_name}.keras')\n    evaluation = model.evaluate(val_ds)\n\n    return model, history, evaluation\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f3c82f3e-964c-44c6-a00a-668ea5b94c63","cell_type":"markdown","source":"# Function to plot training and validation metrics","metadata":{}},{"id":"35e875d7-68ab-4a9a-b0ee-99aec91690ee","cell_type":"code","source":"def plot_metrics(history, model_name):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(len(acc))\n\n    plt.figure(figsize=(10, 5))\n    plt.plot(epochs, acc, 'g', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'y', label='Validation accuracy')\n    plt.title(f'{model_name}: Training and validation accuracy')\n    plt.legend()\n\n    plt.figure(figsize=(10, 5))\n    plt.plot(epochs, loss, 'r', label='Training Loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n    plt.title(f'{model_name}: Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1dfd9e64-0b80-41b5-91e5-4835b7d9bcd8","cell_type":"markdown","source":"# Function to evaluate a model and return accuracy in percentage","metadata":{}},{"id":"4d8e11c5-c18b-4809-8e28-db0925c8be86","cell_type":"code","source":"def evaluate_model(model, dataset, model_name):\n    evaluation = model.evaluate(dataset, verbose=0)\n    accuracy = evaluation[1] * 100 \n    print(f\"{model_name} Accuracy: {accuracy:.2f}%\")\n    return accuracy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6a2f945b-9d74-4986-9519-5d000c782706","cell_type":"markdown","source":"# InceptionV3 for practice","metadata":{}},{"id":"45c716d0-71d3-4e42-843d-d6b31f8da6a8","cell_type":"code","source":"# InceptionV3\nbase_model1 = InceptionV3(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\nmodel1, history1, _ = create_and_train_model(base_model1, 'model1_inceptionv3', train_ds, val_ds, test_ds)\nplot_metrics(history1, 'InceptionV3')\ninceptionv3_accuracy = evaluate_model(model1, val_ds, 'InceptionV3')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"344abae0-cb66-4290-beda-89e4923436fe","cell_type":"markdown","source":"# VGG16","metadata":{}},{"id":"a9998e03-3431-4191-85eb-0ffa98a7bcc3","cell_type":"code","source":"# VGG16\nbase_model2 = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\nmodel2, history2, _ = create_and_train_model(base_model2, 'model2_vgg16', train_ds, val_ds, test_ds)\nplot_metrics(history2, 'VGG16')\nvgg16_accuracy = evaluate_model(model2, val_ds, 'VGG16')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"03e62617-19dc-49c7-856c-e441abbcc343","cell_type":"markdown","source":"# ResNet152V2","metadata":{}},{"id":"963d9324-ca4a-498d-8dee-95e58bee1d42","cell_type":"code","source":"# ResNet152V2\nbase_model3 = ResNet152V2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\nmodel3, history3, _ = create_and_train_model(base_model3, 'model3_resnet152v2', train_ds, val_ds, test_ds)\nplot_metrics(history3, 'ResNet152V2')\nresnet152v2_accuracy = evaluate_model(model3, val_ds, 'ResNet152V2')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8a1ea665-aa16-49e0-ade3-02c3c2893bcb","cell_type":"markdown","source":"# MobileNetV2","metadata":{}},{"id":"928134e7-6c72-490d-ad48-8e70ff854f0f","cell_type":"code","source":"# MobileNetV2\nbase_model4 = MobileNetV2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\nmodel4, history4, _ = create_and_train_model(base_model4, 'model4_mobilenetv2', train_ds, val_ds, test_ds)\nplot_metrics(history4, 'MobileNetV2')\nmobilenetv2_accuracy = evaluate_model(model4, val_ds, 'MobileNetV2')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9d2137a5-7e94-434c-83af-86423604c754","cell_type":"markdown","source":"# Xception","metadata":{}},{"id":"f3945f70-933a-4851-b201-5aee48f490e4","cell_type":"code","source":"# Xception\nbase_model5 = Xception(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\nmodel5, history5, _ = create_and_train_model(base_model5, 'model5_xception', train_ds, val_ds, test_ds)\nplot_metrics(history5, 'Xception')\nxception_accuracy = evaluate_model(model5, val_ds, 'Xception')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2e7edefd-94fd-4bd5-bf6a-38957bfcbaac","cell_type":"markdown","source":"# EfficientNetV2L","metadata":{}},{"id":"26b55e4a-8832-4a97-8fac-1bc258de3584","cell_type":"code","source":"# EfficientNetV2L\nbase_model6 = EfficientNetV2L(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\nmodel6, history6, _ = create_and_train_model(base_model6, 'model6_efficientnetv2l', train_ds, val_ds, test_ds)\nplot_metrics(history6, 'EfficientNetV2L')\nefficientnetv2l_accuracy = evaluate_model(model6, val_ds, 'EfficientNetV2L')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"60e0c162-4a2f-460b-b68b-64a15e246526","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}